{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from networkx.algorithms import connectivity as conn\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tools import utils\n",
    "import networkx as nx\n",
    "import time \n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "os.chdir(\"D:\\Documenti\\Lightning_Network_Logs\\\\recent_logs\")\n",
    "graphs_list = [None] * len(glob.glob(\"*json\"))\n",
    "distance_list = [None] * len(glob.glob(\"*json\"))\n",
    "nodes_size_list = [None] * len(glob.glob(\"*json\"))\n",
    "edges_size_list = [None] * len(glob.glob(\"*json\"))\n",
    "avg_degree_list = [None] * len(glob.glob(\"*json\"))\n",
    "eccentricity_list = [None] * len(glob.glob(\"*json\"))\n",
    "k_connectivity_list = [None] * len(glob.glob(\"*json\"))\n",
    "betweenness_centrality_lists = [None] * len(glob.glob(\"*json\"))\n",
    "# Sets the picture size to a proper dimension.\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Create an array of snapshots of the network\n",
    "for i, file in enumerate(glob.glob(\"*.json\")):\n",
    "    with open(file) as f:\n",
    "        json_graph = json.load(f)\n",
    "        graph = utils.parse_graph_from_json(json_graph)\n",
    "        utils.clean_isolated_nodes(graph)\n",
    "        graph = utils.fix_connectivity(graph)\n",
    "        graphs_list[i] = graph\n",
    "        nodes_size_list[i] = nx.number_of_nodes(graph)\n",
    "        edges_size_list[i] = nx.number_of_edges(graph)\n",
    "        degree_values = [x[1] for x in graph.degree()]\n",
    "        sum_of_edges = sum(degree_values) / float(nx.number_of_nodes(graph))\n",
    "        avg_degree_list[i] = sum_of_edges\n",
    "        last_graph = graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, graph in enumerate(graphs_list):\n",
    "    eccentricity_values = [x[1] for x in nx.eccentricity(graph).items()]\n",
    "    max_eccentricity = max(eccentricity_values)\n",
    "    min_eccentricity = min(eccentricity_values)\n",
    "    eccentricity_list[i] = (max_eccentricity, min_eccentricity)\n",
    "\n",
    "plt.plot(eccentricity_list)\n",
    "plt.savefig('eccentricity.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_degree_list)\n",
    "plt.ylabel('Avg degree')\n",
    "plt.savefig('avg_degree.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nodes_size_list)\n",
    "plt.ylabel('Number of nodes')\n",
    "plt.savefig('number_of_nodes.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(edges_size_list)\n",
    "plt.ylabel('Number of edges')\n",
    "plt.savefig('number_of_edges.png', bbox_inches='tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, graph in enumerate(graphs_list):\n",
    "    distance_list[i] = nx.diameter(graph)\n",
    "\n",
    "plt.plot(distance_list)\n",
    "plt.ylabel('Distance')\n",
    "plt.savefig('distance.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Betweenness Centrality measures for all the snapshot of the network. Returns the subgraph of those network with the most important nodes (BC value greater than 3 times the mean) along with the values returned by the betweenness centality.\n",
    "\n",
    "Then plots the percentage of important nodes (and their respective edges) wrt the total number of nodes and edges.\n",
    "**Average duration for 15 snapshots: 5 mins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_path = r'D:\\Documenti\\Lightning_Network_Logs\\recent_logs\\daily'\n",
    "os.chdir(daily_path)\n",
    "daily_list = [None] * len(glob.glob('*.json'))\n",
    "for i, file in enumerate(glob.glob('*.json')):\n",
    "    with open(file) as f:\n",
    "        graph = utils.parse_graph_from_json(json.load(f))\n",
    "        utils.clean_isolated_nodes(graph)\n",
    "        graph = utils.fix_connectivity(graph)\n",
    "        daily_list[i] = nx.betweenness_centrality(graph)\n",
    "\n",
    "# Sort dictionary of the sums of the betweenness centralities and sort it on their value.\n",
    "sorted_list = sorted(betweenness_centrality_sums.items(), key=lambda x: x[1], reverse=True)\n",
    "# Then select the top five nodes of the sorted list.\n",
    "top_five = [sorted_list[i][0] for i in range(5)]\n",
    "# For each snapshot of betweenness centrality, select the top 5 nodes and their values.\n",
    "top_five_list = dict()\n",
    "for item in top_five:\n",
    "    top_five_list[item] = [daily_list[i][item] for i in range(len(daily_list))]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.xticks(range(number_of_snapshot))\n",
    "for key in top_five_list.keys():\n",
    "    plt.plot(top_five_list[key], label=key[0: 5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, graph in enumerate(graphs_list):\n",
    "    betweenness_centrality_lists[i] = nx.betweenness_centrality(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection of the nodes that persist for all the snapshots\n",
    "utils.betweenness_centrality_intersection(betweenness_centrality_lists)\n",
    "number_of_snapshot = len(betweenness_centrality_lists)\n",
    "\n",
    "# Finds the most important nodes. The evaluation is performed by aggregating the values for all the nodes and selecting\n",
    "# the most important ones.\n",
    "betweenness_centrality_sums = betweenness_centrality_lists[0].copy()\n",
    "for i in range(1, number_of_snapshot):\n",
    "    for key in betweenness_centrality_sums.keys():\n",
    "        betweenness_centrality_sums[key] = betweenness_centrality_sums[key] + betweenness_centrality_lists[i][key]\n",
    "\n",
    "# Sort dictionary of the sums of the betweenness centralities and sort it on their value.\n",
    "sorted_list = sorted(betweenness_centrality_sums.items(), key=lambda x: x[1], reverse=True)\n",
    "# Then select the top five nodes of the sorted list.\n",
    "top_five = [sorted_list[i][0] for i in range(5)]\n",
    "# For each snapshot of betweenness centrality, select the top 5 nodes and their values.\n",
    "top_five_list = dict()\n",
    "for item in top_five:\n",
    "    top_five_list[item] = [betweenness_centrality_lists[i][item] for i in range(number_of_snapshot)]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.xticks(range(number_of_snapshot))\n",
    "for key in top_five_list.keys():\n",
    "    plt.plot(top_five_list[key], label=key[0: 5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as ct\n",
    "\n",
    "gap_dictionary = ct.defaultdict(list)\n",
    "# Builds a presence list among the top 15 nodes over the period observed\n",
    "presence_dict = utils.build_presence_dictionary(betweenness_centrality_lists)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "for item in presence_dict:\n",
    "    start = predecessor = presence_dict[item][0]\n",
    "    for current in presence_dict[item]:\n",
    "        if current - predecessor > 1:\n",
    "            gap = predecessor - start\n",
    "            gap_dictionary[item].append((start, gap))\n",
    "            start = current\n",
    "        predecessor = current\n",
    "    gap = predecessor - start\n",
    "    gap_dictionary[item].append((start, gap))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_xlim(0, 15)\n",
    "ax.set_xticks(range(15))\n",
    "ax.set_xlabel('Snapshots')\n",
    "ax.set_yticks(range(len(gap_dictionary.keys())))\n",
    "ax.set_yticklabels([item[0: 5] for item in gap_dictionary.keys()])\n",
    "ax.grid(True)\n",
    "for i, key in enumerate(gap_dictionary.keys()):\n",
    "    ax.broken_barh(gap_dictionary[key], (i-0.5, 0.8), facecolor='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates k-vertex connectivity, this task is CPU intensive. Average of 5 mins per snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = r'D:\\Documenti\\Lightning_Network_Logs\\recent_logs\\k_conn'\n",
    "utils.removes_satellites(graphs_list[0])\n",
    "if not os.path.exists(new_path):\n",
    "    os.makedirs(new_path)\n",
    "os.chdir(new_path)\n",
    "start = time.time()\n",
    "for i, graph in enumerate(graphs_list): \n",
    "    k_connectivity_list[i] = conn.k_components(graph)\n",
    "    end = time.time()\n",
    "    for key in k_connectivity_list[i].keys():\n",
    "        for j in range(len(k_connectivity_list[i][key])):\n",
    "            k_connectivity_list[i][key][j] = list(k_connectivity_list[i][key][j])\n",
    "    with open('k_conn_' + str(i) + '.json', 'w') as f:\n",
    "        json.dump(k_connectivity_list[i], f, indent=4)\n",
    "    elapsed = end - start\n",
    "    print('Task number ' + str(i) + ' finished in ' + str(elapsed) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the k-vertex connectivity has already been evaluated then run this cell\n",
    "k_conn_path = r'D:\\Documenti\\Lightning_Network_Logs\\recent_logs\\k_conn'\n",
    "k_connectivity_list = utils.read_k_conn_from_files(k_conn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_temp = graphs_list[0].copy()\n",
    "#sub = graph_temp.subgraph(k_connectivity_list[0]['14'][0]).copy()\n",
    "#for node in graphs_list[0].nodes:\n",
    "#    if graph_temp.degree(node) == 1:\n",
    "#        graph_temp.remove_node(node)\n",
    "sub = nx.subgraph(graph_temp, k_connectivity_list[0]['14'][0]).copy()\n",
    "\n",
    "cuts = nx.all_node_cuts(sub)\n",
    "last_cut = None\n",
    "for cut in cuts:\n",
    "    print(cut)\n",
    "    last_cut = cut\n",
    "\n",
    "for node in last_cut:\n",
    "    graph_temp.remove_node(node)\n",
    "    \n",
    "print(nx.is_connected(graph_temp))\n",
    "subgraphs = (graph_temp.subgraph(c) for c in nx.connected_components(graph_temp))\n",
    "for sub in subgraphs:\n",
    "    print(sub.order())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cutsets = [None] * len(graphs_list)\n",
    "for i, graph in enumerate(graphs_list): \n",
    "    cutsets[i] = nx.all_node_cuts(graph)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print('Task number ' + str(i) + ' finished in ' + str(elapsed) + ' seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
